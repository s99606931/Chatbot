# 성능 모니터링

## 1. 성능 지표

### 1.1 핵심 성능 지표(KPI) 모니터링
- **쉽게 설명**: 시스템 성능을 측정하고 관리하는 방법

1. 메트릭 정의
```yaml
# prometheus/rules/performance.yml
groups:
- name: performance_metrics
  rules:
  - record: api_response_time_seconds
    expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
  
  - record: ai_inference_time_seconds
    expr: histogram_quantile(0.95, sum(rate(model_inference_duration_seconds_bucket[5m])) by (le))
  
  - record: database_query_time_seconds
    expr: histogram_quantile(0.95, sum(rate(database_query_duration_seconds_bucket[5m])) by (le))
```

2. 알림 규칙
```yaml
# prometheus/rules/alerts.yml
groups:
- name: performance_alerts
  rules:
  - alert: HighLatency
    expr: api_response_time_seconds > 2
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "API 응답 시간 증가"
      description: "95번째 백분위 응답 시간이 2초를 초과했습니다"
  
  - alert: HighCPUUsage
    expr: cpu_usage_percent > 80
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "CPU 사용량 높음"
      description: "CPU 사용량이 80%를 초과했습니다"
```

### 1.4 AI 성능 모니터링
```yaml
# prometheus/rules/ai-metrics.yml
groups:
- name: ai_performance_metrics
  rules:
  - record: ai_inference_latency_seconds
    expr: histogram_quantile(0.95, sum(rate(ai_inference_duration_seconds_bucket[5m])) by (le, model_version))
    
  - record: ai_accuracy_score
    expr: sum(rate(ai_correct_predictions_total[1h])) / sum(rate(ai_predictions_total[1h]))
    
  - record: ai_error_rate
    expr: sum(rate(ai_error_total[5m])) / sum(rate(ai_requests_total[5m]))

  - alert: HighInferenceLatency
    expr: ai_inference_latency_seconds > 2
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "AI 추론 지연 발생"
      description: "95번째 백분위 추론 시간이 2초를 초과했습니다"
```

### 1.5 실시간 이상 탐지
```python
class AnomalyDetector:
    def __init__(self):
        self.model = IsolationForest(
            contamination=0.1,
            random_state=42
        )
        
    def detect_anomalies(self, metrics: pd.DataFrame) -> List[Anomaly]:
        # 1. 데이터 전처리
        processed_data = self.preprocess_metrics(metrics)
        
        # 2. 이상 탐지
        anomaly_scores = self.model.predict(processed_data)
        
        # 3. 임계값 기반 필터링
        anomalies = self.filter_anomalies(
            anomaly_scores,
            threshold=-0.5
        )
        
        # 4. 알림 생성
        if anomalies:
            self.create_alerts(anomalies)
            
        return anomalies
```

### 1.6 AI 성능 메트릭
```yaml
# prometheus/rules/ai-metrics.yml
groups:
- name: ai_performance_metrics
  rules:
  - record: ai_inference_latency_seconds
    expr: histogram_quantile(0.95, sum(rate(ai_inference_duration_seconds_bucket[5m])) by (le, model_version))
    
  - record: ai_accuracy_score
    expr: sum(rate(ai_correct_predictions_total[1h])) / sum(rate(ai_predictions_total[1h]))
    
  - record: ai_error_rate
    expr: sum(rate(ai_error_total[5m])) / sum(rate(ai_requests_total[5m]))

  - alert: HighInferenceLatency
    expr: ai_inference_latency_seconds > 2
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "AI 추론 지연 발생"
      description: "95번째 백분위 추론 시간이 2초를 초과했습니다"
```

## 2. 모니터링 시스템

### 2.1 Prometheus 설정
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'spring-actuator'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['localhost:8080']

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['localhost:9100']

  - job_name: 'ai-metrics'
    static_configs:
      - targets: ['ai-server:9090']
```

### 2.2 Grafana 대시보드
```javascript
// grafana/dashboards/system-metrics.json
{
  "dashboard": {
    "title": "시스템 성능 대시보드",
    "panels": [
      {
        "title": "API 응답 시간",
        "type": "graph",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "api_response_time_seconds",
            "legendFormat": "응답 시간"
          }
        ]
      },
      {
        "title": "시스템 리소스",
        "type": "graph",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "system_cpu_usage",
            "legendFormat": "CPU 사용률"
          },
          {
            "expr": "system_memory_usage",
            "legendFormat": "메모리 사용률"
          }
        ]
      }
    ]
  }
}
```

## 3. 로그 분석

### 3.1 ELK Stack 구성
```yaml
# logstash/pipeline/main.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [type] == "app" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "erp-chatbot-%{+YYYY.MM.dd}"
  }
}
```

### 3.2 로그 수집 설정
```yaml
# filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/erp-chatbot/*.log
  fields:
    service: erp-chatbot
    environment: production

output.logstash:
  hosts: ["logstash:5044"]
```

## 4. 성능 분석

### 4.1 성능 프로파일링
```java
@Aspect
@Component
public class PerformanceAspect {
    @Around("@annotation(Monitored)")
    public Object measureExecutionTime(ProceedingJoinPoint joinPoint) throws Throwable {
        long startTime = System.currentTimeMillis();
        Object result = joinPoint.proceed();
        long endTime = System.currentTimeMillis();
        
        String methodName = joinPoint.getSignature().getName();
        long duration = endTime - startTime;
        
        // 메트릭 기록
        recordMetric(methodName, duration);
        
        return result;
    }
}
``` 