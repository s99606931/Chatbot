# 구축 절차

## 1. 초기 환경 구성
### 1.1 OS 설치 및 최적화
```bash
# 1. Ubuntu Server 설치
sudo apt update && sudo apt upgrade -y

# 2. 시스템 최적화
cat << EOF | sudo tee /etc/sysctl.d/99-performance.conf
vm.swappiness = 10
vm.dirty_ratio = 10
vm.dirty_background_ratio = 5
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 65535
EOF

# 3. GPU 드라이버 설치
sudo apt install nvidia-driver-535 nvidia-container-toolkit
```

### 1.2 가상화 환경 구성
```bash
# 1. KVM 설치
sudo apt install qemu-kvm libvirt-daemon-system

# 2. GPU Passthrough 설정
sudo vim /etc/default/grub
GRUB_CMDLINE_LINUX_DEFAULT="intel_iommu=on iommu=pt"
sudo update-grub
```

## 2. 컨테이너 환경 구성
### 2.1 K3s 설치
```bash
# 1. K3s 설치
curl -sfL https://get.k3s.io | sh -

# 2. GPU 지원 설정
cat << EOF | sudo tee /var/lib/rancher/k3s/server/manifests/nvidia-device-plugin.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-device-plugin-daemonset
spec:
  template:
    spec:
      containers:
      - image: nvidia/k8s-device-plugin:v0.14.1
        name: nvidia-device-plugin-ctr
EOF
```

## 3. 서비스 배포
### 3.1 데이터베이스 배포
```bash
# 1. 스토리지 클래스 생성
kubectl apply -f storage-class.yaml

# 2. PostgreSQL 배포
kubectl apply -f postgresql-statefulset.yaml

# 3. Redis 배포
kubectl apply -f redis-statefulset.yaml
```

### 3.2 AI 서비스 배포
```bash
# 1. AI 모델 준비
kubectl create configmap llm-config --from-file=models/

# 2. LLM 서비스 배포
kubectl apply -f llm-deployment.yaml

# 3. RAG 서비스 배포
kubectl apply -f rag-deployment.yaml
```